---
title: "DATA 180 Exam 2 - Practice 2"
subtitle: "Spring 2025, Professor Kessler"
output: 
  html_document
---

## Problem 1
Use the following matrix:
```{r}
X <- matrix(c(
  1.5, 2.0,
  1.0, 1.8,
  5.5, 8.0,
  6.0, 9.0,
  1.2, 1.5,
  5.8, 8.6,
  2.1, 2.3,
  6.3, 7.5,
  1.4, 2.2,
  5.1, 9.2
), ncol = 2, byrow = TRUE)
```

a) Run k-means clustering with `k = 2` on the matrix `X`. Increase the number of runs in the model to improve the kmeans fit.
```{r}
kmeans_result <- kmeans(X,2,nstart=50)
```

b) What is the between group sum of squares?
```{r}
kmeans_result$betweenss
```


c) Plot the clusters using base Râ€™s `plot()` function and color by cluster assignment.
```{r}
plot(X[,1],X[,2],col=as.factor(kmeans_result$cluster))
```


## Problem 2

We will use the built-in `iris` dataset for this problem. The dataset includes measurements of sepal and petal length and width for three species of iris flowers.
```{r}
iris
```

a) Use dplyr to calculate the average `Sepal.Width` for each species.
```{r}
iris %>% group_by(Species) %>% summarize(avg=mean(Sepal.Width))
```

b) Create a new variable `area` equal to `Sepal.Length * Petal.Length`. What is the maximum area for plants with pedals no wider than 1.75?
```{r}
iris %>% mutate(area=Sepal.Length*Petal.Width) %>% filter(Petal.Width<1.75) %>% summarize(max_area=max(area))
```

c) What is the number of flowers in each species with a petal length below 4 and a sepal length above 6?
```{r}
iris %>% filter(Petal.Length<4,Sepal.Length>6)
```

d) Run the chunk below to create `iris_sample`.
```{r}
iris_sample <- iris %>% select(Species, Sepal.Length, Sepal.Width)
```

Compute a dissimilarity matrix for `iris_sample`. Be sure to make any necessary transformations to the variables.
```{r}
library(cluster)
output <- iris_sample %>% mutate(Species=as.factor(Species)) %>% daisy() %>% as.matrix()
head(output)
```

## Problem 3
Run the chunk below to import the book, The Time Machine, as well as some necessary packages.
```{r}
text <- scan('TimeMachine.txt', what = "", sep = "\n")
library(quanteda.textstats)
library(quanteda.textplots)
library(quanteda)

char_vec = tolower(text)
```

a) Clean the text using tokenization and removal of stopwords, punctuation, and symbols. Convert to a Term Document Matrix and only retrieve the word stems.
```{r}
tdm <- char_vec %>% tokens(remove_punct=T,remove_symbols=T,remove_numbers=T) %>% tokens_remove(stopwords('en')) %>% dfm() %>% dfm_wordstem()

```


b) Create a wordcloud of the above matrix, but only include words that show up in at least 50 documents.
```{r}
tdm<-dfm_trim(tdm, min_docfreq = 50)
textplot_wordcloud(tdm)
```


## Problem 4: Euclidean Distance

Let the following matrix, M, be defined:
$$
M = \begin{bmatrix}
1 & 5 & 9 & 3 \\
7 & 2 & 6 & 4 \\
3 & 8 & 10 & 2
\end{bmatrix}
$$

a) Compute the Minkowski distance between row 2 and row 3 with a p value of 3.

(|7-3|^3 + |2-8|^3 + |6-10|^3 + |4-2|^3)^1/3 = 3.33

b) Now calculate and print the full distance matrix, do not include the diagonal, but do include the upper triangle.
```{r}
M <- matrix(c(
  1,  5,  9,  3,
  7,  2,  6,  4,
  3,  8, 10, 2
), nrow = 3, byrow = TRUE)

dist(M,method='minkowski',p=3,upper=T)
```

## Problem 5
Consider the following distance matrix
```{r}
D <- matrix(c(
  0, 4.0, 5.2, 3.3, 2.1,
  4.0, 0, 3.7, 6.5, 3.8,
  5.2, 3.7, 0, 4.9, 5.1,
  3.3, 6.5, 4.9, 0, 4.0,
  2.1, 3.8, 5.1, 4.0, 0
), nrow = 5, byrow = TRUE)
```


a) Perform hierarchical clustering using average linkage. Store the result as `hc`. Hint: Remember what type of object the clustering function takes. Is it a matrix?
```{r}
hc<-hclust(as.dist(D),method = 'average')
```

b) Create a dendrogram of your results.
```{r}
plot(hc)
```

c) Add rectangles over dendrogram at the `k=3` level.
```{r}
plot(hc)
rect.hclust(hc,k=3)
```


---

### Problem 6: Linkage Distance Calculation

Given the following distance matrix:

$$
D = \begin{bmatrix}
0 & 2.0 & 3.8 & 5.1 & 4.2 \\
2.0 & 0 & 4.5 & 6.3 & 3.1 \\
3.8 & 4.5 & 0 & 2.9 & 1.7 \\
5.1 & 6.3 & 2.9 & 0 & 2.6 \\
4.2 & 3.1 & 1.7 & 2.6 & 0
\end{bmatrix}
$$

Let Group A = \{O1, O2\} and Group B = \{O3, O4\}

a) Compute the single linkage distance between A and B

min(3.8, 5.1, 4.5, 6.3) = 3.8

b) Compute the complete linkage distance between A and B

max(3.8, 5.1, 4.5, 6.3) = 6.3

c) Compute the average linkage distance between A and B

sum(3.8, 5.1, 4.5, 6.3) / (2*2) = 4.925

## Short Answer

1. What does group_by() do in dplyr?

groups data by the unique values of a column

2. What is the measure in the kmeans clustering algorithm that measures the sum of distances for all observations in a cluster?

Within group/cluster sum of squares

3. What is the default method in the dist() function?

Euclidean

4. What type of match does not necessarily contain useful information in categorical data?

0-0

5. How do we use select() to get rid of a column?

select(-col)

6. What special operator in dplyr let's us take data and move it into another function?

%>% 

7. What do we call a collection of words that we use in concert with some text to determine a type of tone/category?

dictionary

8. What does kmeans()$centers return?

Cluster centroids

9. What does dfm_wordstem() do?

Identifies and retrieves the stem of each token in the DTM

10. What does dfm_trim() accomplish?

Removes words that do not meet certain parameters like a requisite frequency

11. When is the only time mutate() does not append a column to the right hand side?

Modifying a column which already exists

12. Can group_by() use multiple columns?

Yes, group_by(cat1, cat2) works

13. What is the name of the ggplot package that let's us create dendrograms?

ggdendro

14. What does NLP stand for in the context of text analysis?

Natural Language Processing

15. How do you convert a dissimilarity matrix into a similarity matrix?

Similarity = 1-dissimilarity

-

